{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gym\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import copy\n",
    "import seaborn as sns\n",
    "\n",
    "from RLEnvironment import TaxiQLearner, UserTaxiEnvironment\n",
    "from InverseReinforcementLearning import max_entropy\n",
    "from EvaluationTools import compare_Q_matrices, simulate_episodes, actionable_sparse_Q_learning, greedy_baseline, sparse_Q_learning\n",
    "\n",
    "# SEED EVERYTHING\n",
    "RANDOM_SEED = 123\n",
    "np.random.seed(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Initializing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|\u001b[34;1mR\u001b[0m: | : :G|\n",
      "| : |\u001b[43m \u001b[0m: : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|\u001b[35mY\u001b[0m| : |B: |\n",
      "+---------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[123]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize the RL Environment\n",
    "rl_env = gym.make(\"Taxi-v3\").env # Initializing the RL environment THIS SHOULD ONLY BE DONE ONCE (since the RL environment for the IRL and the recourse should be the same)\n",
    "rl_env.render() # Show how the RL environment looks\n",
    "rl_env.seed(RANDOM_SEED)\n",
    "rl_env.action_space.seed(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 0 latest length 648\n",
      "Episode 25 latest length 1334\n",
      "Episode 50 latest length 104\n",
      "Episode 75 latest length 78\n",
      "Episode 100 latest length 115\n",
      "Episode 125 latest length 28\n",
      "Episode 150 latest length 11\n",
      "Episode 175 latest length 16\n",
      "Episode 200 latest length 31\n",
      "Episode 225 latest length 253\n",
      "Episode 250 latest length 23\n",
      "Episode 275 latest length 577\n",
      "Episode 300 latest length 71\n",
      "Episode 325 latest length 142\n",
      "Episode 350 latest length 18\n",
      "Episode 375 latest length 16\n",
      "Episode 400 latest length 58\n",
      "Episode 425 latest length 12\n",
      "Episode 450 latest length 23\n",
      "Episode 475 latest length 22\n",
      "Episode 500 latest length 10\n",
      "Episode 525 latest length 40\n",
      "Episode 550 latest length 35\n",
      "Episode 575 latest length 17\n",
      "Episode 600 latest length 19\n",
      "Episode 625 latest length 301\n",
      "Episode 650 latest length 20\n",
      "Episode 675 latest length 12\n",
      "Episode 700 latest length 14\n",
      "Episode 725 latest length 20\n",
      "Episode 750 latest length 18\n",
      "Episode 775 latest length 261\n",
      "Episode 800 latest length 13\n",
      "Episode 825 latest length 16\n",
      "Episode 850 latest length 88\n",
      "Episode 875 latest length 160\n",
      "Episode 900 latest length 43\n",
      "Episode 925 latest length 30\n",
      "Episode 950 latest length 21\n",
      "Episode 975 latest length 23\n"
     ]
    }
   ],
   "source": [
    "# Initialize the User's Policy\n",
    "user_agent = TaxiQLearner(rl_env)\n",
    "user_agent.epsilon = 0.1 \n",
    "train_data, train_rewards, train_lengths = user_agent.train(1000) \n",
    "\n",
    "# Needs to be suboptimal, so randomly change the Q\n",
    "random_states = np.random.choice(range(500), 50, replace = False)\n",
    "user_agent.Q[random_states, :] = np.zeros((random_states.shape[0], 6))\n",
    "random_action = np.random.choice(range(0, 6), random_states.shape[0], replace = True)\n",
    "for i, ind in enumerate(random_action): \n",
    "    user_agent.Q[random_states[i], ind] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n"
     ]
    }
   ],
   "source": [
    "# Generate trajectory data\n",
    "user_data = []\n",
    "for episode in range(500): # This is the number of trajectories you want\n",
    "    if episode % 100 == 0: \n",
    "        print(episode)\n",
    "    D, r = user_agent.run_episode(train = False)\n",
    "    user_data.append(D)\n",
    "        \n",
    "user_trajectories = []\n",
    "for data in user_data: \n",
    "    df = pd.DataFrame(data, columns = [\n",
    "      'prev_taxi_row', \n",
    "      'prev_taxi_column',\n",
    "      'prev_passenger_loc',\n",
    "      'prev_destination',\n",
    "      'prev_state',\n",
    "      'action',\n",
    "      'reward', # this is the true environment rewards\n",
    "      'new_taxi_row', \n",
    "      'new_taxi_column',\n",
    "      'new_passenger_loc',\n",
    "      'new_destination',\n",
    "      'new_state'])\n",
    "    user_trajectories.append(df)\n",
    "    \n",
    "# The ground truth Q\n",
    "user_ground_truth_Q = np.copy(user_agent.Q)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Inferring the user's policy\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0\n",
      "[0.3  0.1  0.05 0.05 0.03 0.   0.03 0.01 0.   0.07]\n",
      "Backward pass...\n",
      "Forward pass...\n",
      "100/6660\n",
      "200/6660\n",
      "300/6660\n",
      "400/6660\n",
      "500/6660\n",
      "600/6660\n",
      "700/6660\n",
      "800/6660\n",
      "900/6660\n",
      "1000/6660\n",
      "1100/6660\n",
      "1200/6660\n",
      "1300/6660\n",
      "1400/6660\n",
      "1500/6660\n",
      "1600/6660\n",
      "1700/6660\n",
      "1800/6660\n",
      "1900/6660\n",
      "2000/6660\n",
      "2100/6660\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-3fd64e860acd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Perform IRL\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0muser_reward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mme\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_entropy_irl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/fall2020/CS282_MDP_Game_Recourse/InverseReinforcementLearning.py\u001b[0m in \u001b[0;36mmax_entropy_irl\u001b[0;34m(self, feature_map)\u001b[0m\n\u001b[1;32m    208\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m         \u001b[0;31m# compute gradient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 210\u001b[0;31m         \u001b[0mstate_visitation_frequency\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpected_state_visitation_frequency\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser_reward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_trajectories\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# part 2 of gradient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    211\u001b[0m         \u001b[0;31m#state_visitation_frequency = self.expected_state_visitation_frequency_deterministic(reward_weight)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/fall2020/CS282_MDP_Game_Recourse/InverseReinforcementLearning.py\u001b[0m in \u001b[0;36mexpected_state_visitation_frequency\u001b[0;34m(self, user_reward, batch_trajectories)\u001b[0m\n\u001b[1;32m    156\u001b[0m         \u001b[0;31m# Get all states that could lead to current\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m         \u001b[0mtransition_to\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mP\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms_to\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 158\u001b[0;31m         \u001b[0mstate_action_froms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransition_to\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# states, actions that lead to s_to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    159\u001b[0m         \u001b[0ms_from_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate_action_froms\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "me = max_entropy(trajectories = user_trajectories, epochs = 10, learning_rate = 0.001, epsilon = 0., environment = rl_env, minibatch_size = 100)\n",
    "\n",
    "# create feature map\n",
    "feature_map = np.eye(500) # One hot encoding of the state vector\n",
    "\n",
    "# Perform IRL\n",
    "user_reward, grads = me.max_entropy_irl(feature_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Do we learn a decent approximation of the user's behavior policy? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 0\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'user_reward' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-e20621c8ef5e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_trials\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Trial {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0muser_env\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mUserTaxiEnvironment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser_reward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrl_env\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmultiplier\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;36m1.\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Define a user environment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mlearned_user_agent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTaxiQLearner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser_env\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepsilon\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlearned_user_agent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'user_reward' is not defined"
     ]
    }
   ],
   "source": [
    "num_trials = 1\n",
    "random_Q_results = np.zeros(num_trials)\n",
    "learned_Q_results = np.zeros(num_trials)\n",
    "\n",
    "for j in range(num_trials): \n",
    "    print(\"Trial {}\".format(j))\n",
    "    user_env = UserTaxiEnvironment(user_reward, rl_env, multiplier= 1.) # Define a user environment\n",
    "    learned_user_agent = TaxiQLearner(user_env, epsilon = 0.4)\n",
    "    _ = learned_user_agent.train(1000)\n",
    "    \n",
    "    # Random Q matrix\n",
    "    random_Q = np.zeros((500, 6))\n",
    "    random_actions = (np.random.choice(range(6), 500))\n",
    "    for i, action in enumerate(random_actions):\n",
    "        random_Q[i, action] = 1\n",
    "\n",
    "\n",
    "    learned_Q_results[j] = compare_Q_matrices(learned_user_agent.Q, user_agent.Q)\n",
    "    random_Q_results[j] = compare_Q_matrices(random_Q, user_agent.Q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the action-selection similarilty scores\n",
    "data = np.vstack((learned_Q_results, random_Q_results)).T\n",
    "results_df = pd.DataFrame(data = data, columns = ['Learned user Q', 'Random user Q'])\n",
    "sns.boxplot(data = results_df)\n",
    "plt.ylabel(\"No. actions matching true Q\")\n",
    "plt.savefig('random_learned_boxplots.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-589d5d88d9f1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Visualize the Q-matrices\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0msns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheatmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser_agent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mQ\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0msns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheatmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearned_user_agent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mQ\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "# Visualize the Q-matrices\n",
    "fig, ax = plt.subplots(1, 3, figsize=(20, 5))\n",
    "\n",
    "sns.heatmap(user_agent.Q[:50, :], ax=ax[0])\n",
    "sns.heatmap(learned_user_agent.Q[:50, :], ax=ax[1])\n",
    "sns.heatmap(random_Q[:50, :], ax=ax[2])\n",
    "\n",
    "ax[0].set_title(\"User's ground truth Q\")\n",
    "ax[1].set_title(\"IRL learned Q\")\n",
    "ax[2].set_title(\"Randomly generated Q\")\n",
    "plt.savefig('Learned_Q_matrices.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'learned_user_agent' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-b22379a09f6a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# learned user agent Q using the IRL user reward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0muser_Q\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlearned_user_agent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mQ\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# evaluate the user_agent with user_Q in the original environment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0muser_agent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTaxiQLearner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrl_env\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepsilon\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'learned_user_agent' is not defined"
     ]
    }
   ],
   "source": [
    "# learned user agent Q using the IRL user reward\n",
    "user_Q = learned_user_agent.Q.copy()\n",
    "\n",
    "# evaluate the user_agent with user_Q in the original environment\n",
    "user_agent = TaxiQLearner(rl_env, epsilon = 0.3)\n",
    "user_agent.Q = user_Q\n",
    "\n",
    "# get the expected return for the user agent\n",
    "user_avg_steps = simulate_episodes(user_agent, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Improving the user's policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 0 latest length 61\n",
      "Evaluating Current New Policy\n",
      "Evaluation episode 0: 65 steps\n",
      "Evaluation episode 25: 144 steps\n",
      "Evaluation episode 50: 11110 steps\n",
      "Evaluation episode 75: 189 steps\n",
      "Current Return: 147.5\n",
      "Episode 0 latest length 95\n",
      "Evaluating Current New Policy\n",
      "Evaluation episode 0: 315 steps\n",
      "Evaluation episode 25: 349 steps\n",
      "Evaluation episode 50: 29 steps\n",
      "Evaluation episode 75: 162 steps\n",
      "Current Return: 131.0\n",
      "Episode 0 latest length 19\n",
      "Evaluating Current New Policy\n",
      "Evaluation episode 0: 295 steps\n",
      "Evaluation episode 25: 205 steps\n",
      "Evaluation episode 50: 18 steps\n",
      "Evaluation episode 75: 709 steps\n",
      "Current Return: 108.0\n",
      "Episode 0 latest length 82\n",
      "Evaluating Current New Policy\n",
      "Evaluation episode 0: 18 steps\n",
      "Evaluation episode 25: 17 steps\n",
      "Evaluation episode 50: 2789 steps\n",
      "Evaluation episode 75: 249 steps\n",
      "Current Return: 114.0\n",
      "Episode 0 latest length 19\n",
      "Evaluating Current New Policy\n",
      "Evaluation episode 0: 14 steps\n",
      "Evaluation episode 25: 64 steps\n",
      "Evaluation episode 50: 80 steps\n",
      "Evaluation episode 75: 3189 steps\n",
      "Current Return: 95.5\n",
      "Episode 0 latest length 24\n",
      "Evaluating Current New Policy\n",
      "Evaluation episode 0: 17 steps\n",
      "Evaluation episode 25: 57 steps\n",
      "Evaluation episode 50: 144 steps\n",
      "Evaluation episode 75: 205 steps\n",
      "Current Return: 124.5\n",
      "Episode 0 latest length 104\n",
      "Evaluating Current New Policy\n",
      "Evaluation episode 0: 241 steps\n",
      "Evaluation episode 25: 122 steps\n"
     ]
    }
   ],
   "source": [
    "user_agent_Q = user_agent.Q.copy()\n",
    "\n",
    "norms = []\n",
    "reward_threshs = range(50, 150, 10)\n",
    "for reward in reward_threshs:\n",
    "    improved_agent = TaxiQLearner(rl_env)\n",
    "    improved_agent.Q = user_agent_Q.copy()\n",
    "    improved_agent.epsilon = 0.3\n",
    "    \n",
    "    # Train and evaluate\n",
    "    current_return = reward + 1\n",
    "    i = 0 \n",
    "    while current_return > reward and i < 100: \n",
    "        train_data, train_rewards, train_lengths = user_agent.train(1, user_Q = user_agent_Q, sparse_penalty = 0.5) \n",
    "        if i % 5 == 0: \n",
    "            print(\"Evaluating Current New Policy\")\n",
    "            total_steps, _, _ = user_agent.evaluate(100)\n",
    "            current_return = np.median(total_steps)\n",
    "            print(\"Current Return: {}\".format(current_return))\n",
    "    print(\"DONE!\\n\")\n",
    "    #user_agent_Q = user_agent.Q.copy()\n",
    "    #new_user, new_user_return = sparse_Q_learning(rl_env, user_agent_Q, max_iters=100, goal_reward=reward, penalty=0.5, epsilon = 0.4, alpha = 0.75)\n",
    "    current_norm = np.linalg.norm(user_agent_Q - improved_agent.Q, ord = 1)\n",
    "    norms.append(current_norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing User Preference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6 actions: south, north, east, west, pickup passenger, dropoff passenger\n",
    "# we assume that taxi user does not like taking left turns \n",
    "# so we downweight action 3\n",
    "avoid_left_turns = lambda s, a: -10 if (a == 3) else -5\n",
    "\n",
    "new_user, new_user_return, user_return = actionable_sparse_Q_learning(user_agent_Q, max_iters=20, min_diff=20, percentage_diff=0.15, penalty=avoid_left_turns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results for the Greedy Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learn the optimal Q value using the true reward\n",
    "optimal_user_agent = TaxiQLearner(rl_env, epsilon = 0.3)\n",
    "_ = optimal_user_agent.train(500)\n",
    "optimal_Q = optimal_user_agent.Q.copy()\n",
    "# get the expected return for the optimal user agent\n",
    "optimal_user_avg_steps = simulate_episodes(optimal_user_agent, num_episodes_evaluation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the absolute difference between the optimal Q \n",
    "Q_diff = abs(optimal_Q - user_Q)\n",
    "# sum of abs diff per state\n",
    "Q_diff_state = Q_diff.sum(axis = 1)\n",
    "print('number of the absolute differences that are 0 out of 500 differences: {}'.format(\n",
    "    (Q_diff_state ==0).sum()))\n",
    "print('number of distinct non-zero abs differences: {}'.format(\n",
    "    len(set(Q_diff_state[Q_diff_state != 0]))))\n",
    "\n",
    "# if there is no duplicate values, then we can use the abs difference as the key of the dict\n",
    "# a dictionary of tuple: key = abs difference, value = row (state)\n",
    "abs_diff_dict = dict()\n",
    "for state, abs_diff in enumerate(Q_diff_state):\n",
    "    if abs_diff != 0:\n",
    "        abs_diff_dict[abs_diff] = state\n",
    "\n",
    "# sort the absolute difference in the ascending order\n",
    "sorted_abs_diff = sorted(abs_diff_dict.keys(), reverse = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_diff = user_avg_steps # how much we want to improve the average user steps\n",
    "\n",
    "i = 0\n",
    "current_abs_diff = sorted_abs_diff[0] # ith smallest abs diff\n",
    "# get the [s,{a}] to be changed\n",
    "state_changed = abs_diff_dict[current_abs_diff]\n",
    "# change Q user [s,a] to optimal Q[s,a]\n",
    "current_Q = user_Q.copy()\n",
    "current_Q[state_changed, :] = optimal_Q[state_changed, :]\n",
    "\n",
    "# evaluate the current Q on the original RL environment\n",
    "current_user_agent = TaxiQLearner(rl_env, epsilon = 0.4)\n",
    "current_user_agent.Q = current_Q\n",
    "current_user_avg_steps = simulate_episodes(current_user_agent, 100)\n",
    "\n",
    "# keep track of current user avg_steps\n",
    "list_avg_step_history = [user_avg_steps, current_user_avg_steps]\n",
    "list_Q_diff = [0, current_abs_diff]\n",
    "\n",
    "# stop if current return <= user_avg_steps - some constant\n",
    "while ((current_user_avg_steps > user_avg_steps - min_diff) and i < len(abs_diff_dict) - 1):\n",
    "    i += 1\n",
    "    # keep updating current user Q\n",
    "    current_abs_diff = sorted_abs_diff[i] # ith smallest abs diff\n",
    "    # get the [s,a] to be changed\n",
    "    state_changed = abs_diff_dict[current_abs_diff]\n",
    "    # change Q user [s,a] to optimal Q[s,a]\n",
    "    current_Q[state_changed, :] = optimal_Q[state_changed, :]\n",
    "    \n",
    "    # evaluate the current Q on the original RL environment\n",
    "    current_user_agent = TaxiQLearner(rl_env, epsilon = 0.4)\n",
    "    current_user_agent.Q = current_Q\n",
    "    current_user_avg_steps = simulate_episodes(current_user_agent, 100)\n",
    "    print('iteration: {}, avg steps: {}'.format(i, current_user_avg_steps))\n",
    "    \n",
    "    list_avg_step_history.append(current_user_avg_steps)\n",
    "    list_Q_diff.append(list_Q_diff[-1] + current_abs_diff)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results for Our Method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison of Greedy vs. Our method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "baseline_res = pickle.load(open(\"baseline.pickle\", \"rb\"))\n",
    "our_res = pickle.load(open(\"method.pickle\", \"rb\"))\n",
    "\n",
    "baseline_norms = np.array(baseline_res[\"list_Q_diff\"])\n",
    "baseline_lengths = np.array(baseline_res[\"list_avg_step_history\"])\n",
    "our_norms = np.array(our_res[\"norms\"])\n",
    "our_lengths = np.array(our_res[\"reward_threshs\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'list_Q_diff': [37.45620314585692,\n",
       "  25.541273402072488,\n",
       "  1.7343786219090906,\n",
       "  0.4959814006382462,\n",
       "  0.4959814006382462,\n",
       "  0.4959814006382462,\n",
       "  0.4959814006382462,\n",
       "  0.4959814006382462,\n",
       "  0.4959814006382462,\n",
       "  0.4959814006382462],\n",
       " 'list_avg_step_history': [47.5,\n",
       "  58.5,\n",
       "  70.0,\n",
       "  72.5,\n",
       "  73.0,\n",
       "  80.5,\n",
       "  104.5,\n",
       "  71.0,\n",
       "  92.0,\n",
       "  102.0]}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(10, 6))\n",
    "baseline_ind = list(range(0, len(baseline_res[\"list_avg_step_history\"]), 50))\n",
    "\n",
    "ax.scatter(baseline_lengths, baseline_norms, color = \"red\", alpha = 0.5, label=\"Greedy Baseline\")\n",
    "ax.scatter(our_lengths, our_norms, color=\"blue\", alpha = 0.5, label=\"Our Method\")\n",
    "\n",
    "#ax.set_title('Steps taken to success versus Sparsity of counterfactual', fontsize = 14)\n",
    "plt.xlabel('Episode Length')\n",
    "plt.ylabel('Difference in Q matrices (norm)')\n",
    "\n",
    "# fit a regression line\n",
    "m_baseline, b_baseline = np.polyfit(baseline_lengths, baseline_norms, 1)\n",
    "m_ours, b_ours = np.polyfit(our_lengths, our_norms, 1)\n",
    "\n",
    "plt.plot(baseline_lengths, m_baseline*baseline_lengths + b_baseline, color = 'red', label = 'slope = {}'.format(np.round(m_baseline, 2)))\n",
    "plt.plot(our_lengths, m_ours*our_lengths + b_ours, color = 'blue', label = 'slope = {}'.format(np.round(m_ours, 2)))\n",
    "#plt.ylim((-100, 2600))\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([51.15878533, 51.15878533, 51.15878533, 51.15878533,  7.67013817,\n",
       "        0.28463933,  0.05212735,  0.05212735,  0.        ,  0.        ])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "our_norms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.76385414, 88.25428243])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.polyfit(baseline_res[\"list_avg_step_history\"],  baseline_res[\"list_Q_diff\"], 1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
